{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automacao de Negocios - Mes Seguinte Escondido",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+g7P2w4qXgtRznqbCz6nu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htsnet/automacao-de-negocios/blob/master/Automacao_de_Negocios_Mes_Seguinte_Escondido.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XIrIoBwb1NN",
        "colab_type": "text"
      },
      "source": [
        "#Uma variação do notebook original, sem split e uso do mês seguinte como validador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esQEmXvQUDAO",
        "colab_type": "text"
      },
      "source": [
        "# Início: Importação as bibliotecas e Arquivo\n",
        "É preciso carregar um arquivo CSV com o padrão definido para execução do notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60MYovA_7su6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2ae007-7009-42b0-db78-f98715f3330f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from matplotlib.pyplot import figure\n",
        "import datetime\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n",
        "import seaborn as sns\n",
        "# TensorFlow e tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lrF2JfV8RVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#carrega a tabela de dados\n",
        "#separador de campos = ;\n",
        "#ponto decimal = ,\n",
        "historic = pd.read_csv(\"/content/Amostra Completa - Mercado Futuro.csv\", sep=\";\", decimal=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSeb5skcepaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "78849109-4189-43bb-f03e-e3145057e22a"
      },
      "source": [
        "#converte o campo data (string) em formato de data\n",
        "historic['DataFormatada'] = pd.to_datetime(historic['Data'], format='%d/%m/%Y')\n",
        "historic.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CodOp</th>\n",
              "      <th>Hora Entrada</th>\n",
              "      <th>Hora Saida</th>\n",
              "      <th>Duração</th>\n",
              "      <th>Data</th>\n",
              "      <th>Pentrada</th>\n",
              "      <th>Psaida</th>\n",
              "      <th>Ganhos</th>\n",
              "      <th>Perdas</th>\n",
              "      <th>Resultado</th>\n",
              "      <th>Saldo Trade</th>\n",
              "      <th>K entra</th>\n",
              "      <th>K Saida</th>\n",
              "      <th>Item 1</th>\n",
              "      <th>Item 2</th>\n",
              "      <th>Item 3</th>\n",
              "      <th>Item 4</th>\n",
              "      <th>Item 5</th>\n",
              "      <th>Item 6</th>\n",
              "      <th>Item 7</th>\n",
              "      <th>Item 8</th>\n",
              "      <th>Item 9</th>\n",
              "      <th>Item 10</th>\n",
              "      <th>Item 11</th>\n",
              "      <th>Item 12</th>\n",
              "      <th>Item 13</th>\n",
              "      <th>Item 14</th>\n",
              "      <th>Item 15</th>\n",
              "      <th>Item 16</th>\n",
              "      <th>Item 17</th>\n",
              "      <th>Item 18</th>\n",
              "      <th>Item 19</th>\n",
              "      <th>Item 20</th>\n",
              "      <th>Item 21</th>\n",
              "      <th>Item 22</th>\n",
              "      <th>Item 23</th>\n",
              "      <th>Item 24</th>\n",
              "      <th>Item 25</th>\n",
              "      <th>Item 26</th>\n",
              "      <th>Item 27</th>\n",
              "      <th>...</th>\n",
              "      <th>Item 39</th>\n",
              "      <th>Item 40</th>\n",
              "      <th>Item 41</th>\n",
              "      <th>Item 42</th>\n",
              "      <th>Item 43</th>\n",
              "      <th>Item 44</th>\n",
              "      <th>Item 45</th>\n",
              "      <th>Item 46</th>\n",
              "      <th>Item 47</th>\n",
              "      <th>Item 48</th>\n",
              "      <th>Item 49</th>\n",
              "      <th>Item 50</th>\n",
              "      <th>Item 51</th>\n",
              "      <th>Item 52</th>\n",
              "      <th>Item 53</th>\n",
              "      <th>Item 54</th>\n",
              "      <th>Item 55</th>\n",
              "      <th>Item 56</th>\n",
              "      <th>Item 57</th>\n",
              "      <th>Item 58</th>\n",
              "      <th>Item 59</th>\n",
              "      <th>Item 60</th>\n",
              "      <th>Item 61</th>\n",
              "      <th>Item 62</th>\n",
              "      <th>Item 63</th>\n",
              "      <th>Item 64</th>\n",
              "      <th>Item 65</th>\n",
              "      <th>Item 66</th>\n",
              "      <th>Item 67</th>\n",
              "      <th>Item 68</th>\n",
              "      <th>Item 69</th>\n",
              "      <th>Item 70</th>\n",
              "      <th>Item 71</th>\n",
              "      <th>Item 72</th>\n",
              "      <th>Item 73</th>\n",
              "      <th>Item 74</th>\n",
              "      <th>Item 75</th>\n",
              "      <th>Item 76</th>\n",
              "      <th>Item 77</th>\n",
              "      <th>DataFormatada</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9601</td>\n",
              "      <td>11:00:14</td>\n",
              "      <td>11:14:14</td>\n",
              "      <td>00:13:59</td>\n",
              "      <td>02/01/2019</td>\n",
              "      <td>3876.5</td>\n",
              "      <td>3862.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>54400</td>\n",
              "      <td>-1800</td>\n",
              "      <td>-11.5</td>\n",
              "      <td>24</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>6800.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>11400.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>37.5</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-58</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>-66</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>-60</td>\n",
              "      <td>...</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>41</td>\n",
              "      <td>27</td>\n",
              "      <td>37</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>500</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1500</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>440</td>\n",
              "      <td>-11</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-8.5</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>-8.5</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>-6.5</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2019-01-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9602</td>\n",
              "      <td>11:01:15</td>\n",
              "      <td>11:14:29</td>\n",
              "      <td>00:13:14</td>\n",
              "      <td>02/01/2019</td>\n",
              "      <td>3874.5</td>\n",
              "      <td>3859.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2</td>\n",
              "      <td>-15.5</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>57600</td>\n",
              "      <td>-2200</td>\n",
              "      <td>-13.5</td>\n",
              "      <td>24</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>6800.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>11400.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>37.5</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.08</td>\n",
              "      <td>-68</td>\n",
              "      <td>-0.88</td>\n",
              "      <td>-64</td>\n",
              "      <td>...</td>\n",
              "      <td>33</td>\n",
              "      <td>37</td>\n",
              "      <td>36</td>\n",
              "      <td>27</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>200</td>\n",
              "      <td>700</td>\n",
              "      <td>500</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>-2800</td>\n",
              "      <td>-1500</td>\n",
              "      <td>90</td>\n",
              "      <td>6690</td>\n",
              "      <td>440</td>\n",
              "      <td>-12</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-11.5</td>\n",
              "      <td>-8.5</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-11.5</td>\n",
              "      <td>-7.5</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2019-01-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9603</td>\n",
              "      <td>11:02:16</td>\n",
              "      <td>11:19:46</td>\n",
              "      <td>00:17:30</td>\n",
              "      <td>02/01/2019</td>\n",
              "      <td>3872.5</td>\n",
              "      <td>3858.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>2</td>\n",
              "      <td>-14.5</td>\n",
              "      <td>120</td>\n",
              "      <td>140</td>\n",
              "      <td>57600</td>\n",
              "      <td>-2400</td>\n",
              "      <td>-15.5</td>\n",
              "      <td>24</td>\n",
              "      <td>470.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>1160.0</td>\n",
              "      <td>6800.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>11400.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>37.5</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-54</td>\n",
              "      <td>-0.82</td>\n",
              "      <td>-70</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>-68</td>\n",
              "      <td>...</td>\n",
              "      <td>19</td>\n",
              "      <td>38</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>34</td>\n",
              "      <td>36</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>1000</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-400</td>\n",
              "      <td>-5500</td>\n",
              "      <td>20</td>\n",
              "      <td>110</td>\n",
              "      <td>19650</td>\n",
              "      <td>-14</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-11.5</td>\n",
              "      <td>-14.5</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>-12.5</td>\n",
              "      <td>-14.5</td>\n",
              "      <td>-8.5</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2019-01-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9604</td>\n",
              "      <td>11:03:18</td>\n",
              "      <td>11:19:46</td>\n",
              "      <td>00:16:28</td>\n",
              "      <td>02/01/2019</td>\n",
              "      <td>3872.0</td>\n",
              "      <td>3858.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>125</td>\n",
              "      <td>140</td>\n",
              "      <td>57600</td>\n",
              "      <td>-2400</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>24</td>\n",
              "      <td>480.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>1720.0</td>\n",
              "      <td>6800.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>11400.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>37.5</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-64</td>\n",
              "      <td>-0.94</td>\n",
              "      <td>-68</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-68</td>\n",
              "      <td>...</td>\n",
              "      <td>18</td>\n",
              "      <td>33</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>35</td>\n",
              "      <td>-100</td>\n",
              "      <td>100</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>-800</td>\n",
              "      <td>0</td>\n",
              "      <td>-5500</td>\n",
              "      <td>170</td>\n",
              "      <td>20</td>\n",
              "      <td>19650</td>\n",
              "      <td>-14</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>-12.5</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2019-01-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9605</td>\n",
              "      <td>11:04:39</td>\n",
              "      <td>11:19:46</td>\n",
              "      <td>00:15:07</td>\n",
              "      <td>02/01/2019</td>\n",
              "      <td>3872.0</td>\n",
              "      <td>3858.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>125</td>\n",
              "      <td>140</td>\n",
              "      <td>60800</td>\n",
              "      <td>-2400</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>24</td>\n",
              "      <td>480.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>680.0</td>\n",
              "      <td>6800.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>11400.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>37.5</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-64</td>\n",
              "      <td>-0.96</td>\n",
              "      <td>-66</td>\n",
              "      <td>-0.88</td>\n",
              "      <td>-68</td>\n",
              "      <td>...</td>\n",
              "      <td>21</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>23</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>1000</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5500</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>19650</td>\n",
              "      <td>-14</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>-12.5</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-8.5</td>\n",
              "      <td>-12.5</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2019-01-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   CodOp Hora Entrada Hora Saida  ... Item 76 Item 77  DataFormatada\n",
              "0   9601     11:00:14   11:14:14  ...     2.9     5.4     2019-01-02\n",
              "1   9602     11:01:15   11:14:29  ...     2.9     5.4     2019-01-02\n",
              "2   9603     11:02:16   11:19:46  ...     2.0     5.4     2019-01-02\n",
              "3   9604     11:03:18   11:19:46  ...     1.8     5.4     2019-01-02\n",
              "4   9605     11:04:39   11:19:46  ...     1.6     5.4     2019-01-02\n",
              "\n",
              "[5 rows x 91 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0NU0d09etBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separa um mês em cada  dataframe e faz todas as operações de preparação do daframe criado\n",
        "variables = locals()\n",
        "for i in range(1,13):\n",
        "  mes = str(i).zfill(2)\n",
        "  variables[\"mes{0}\".format(mes)] = historic[historic['DataFormatada'].dt.month == i]\n",
        "  #separa o target e o código da operação\n",
        "  variables[\"target{0}\".format(mes)] = variables[\"mes{0}\".format(mes)][['CodOp', 'Resultado']].copy()\n",
        "  #indica o campo CodOp como índice nos 2 dataframes (para conferência futura)\n",
        "  variables[\"mes{0}\".format(mes)] = variables[\"mes{0}\".format(mes)].set_index('CodOp')\n",
        "  variables[\"target{0}\".format(mes)] = variables[\"target{0}\".format(mes)].set_index('CodOp')\n",
        "  #apaga o campo target do dataframe original e outros campos já definidos como não necessários\n",
        "  variables[\"mes{0}\".format(mes)] = variables[\"mes{0}\".format(mes)].drop(['Resultado', 'Hora Entrada', 'Hora Saida',\n",
        "                                                                          'Duração', 'Data', 'Pentrada', 'Psaida', 'Ganhos',\n",
        "                                                                          'Perdas', 'Saldo Trade', 'K entra', 'K Saida', 'DataFormatada'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8F3MP9kEwiM",
        "colab_type": "text"
      },
      "source": [
        "# Criando um arquivo separado com base no mês para teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viwaY_ZVcXyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#escolhas dos meses para tratar\n",
        "mesesTreino = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11'] #train\n",
        "mesValidacao = '12' #test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U267JxQ7co9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "42292d86-a954-4183-a99b-90c9c573163d"
      },
      "source": [
        "#prepara os datasets de acordo com os meses informados\n",
        "variables = locals()\n",
        "X_train = variables[\"mes{}\".format(mesesTreino[0])].copy()\n",
        "for i in range(1, len(mesesTreino)):\n",
        "  X_train = X_train.append(variables[\"mes{}\".format(mesesTreino[i])])\n",
        "print(X_train.shape)\n",
        "\n",
        "X_test = variables[\"mes{}\".format(mesValidacao)].copy()\n",
        "print(X_test.shape)\n",
        "\n",
        "#e também dos objetivos para validação\n",
        "y_train = variables[\"target{}\".format(mesesTreino[0])].copy()\n",
        "for i in range(1, len(mesesTreino)):\n",
        "  y_train = y_train.append(variables[\"target{}\".format(mesesTreino[i])])\n",
        "print(y_train.shape)\n",
        "\n",
        "y_test = variables[\"target{}\".format(mesValidacao)].copy()\n",
        "print(y_test.shape)\n",
        "#converte em array\n",
        "y_test = y_test.values.ravel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36102, 77)\n",
            "(2966, 77)\n",
            "(36102, 1)\n",
            "(2966, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tirV7EfFNGL",
        "colab_type": "text"
      },
      "source": [
        "# Modelagem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckOdL07AgUaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definição de parâmetros para todos os classificadores\n",
        "estimadores = 200\n",
        "quantidadeValidacaoCruzada = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l--Hx-lwho53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a apresentação dos resultados das modelagens\n",
        "def mostraResultado(y_test, valoresPrevistos):\n",
        "  #lista quantidade de acertos\n",
        "  contaOk = 0\n",
        "  contaNao = 0\n",
        "  contaDesconsiderados = 0\n",
        "  for i in range(0, len(y_test)):\n",
        "    if valoresPrevistos[i] == 1  and y_test[i] == 1:\n",
        "      contaOk += 1\n",
        "    elif valoresPrevistos[i] == 1  and y_test[i] == 2:\n",
        "      contaNao += 1\n",
        "    else:\n",
        "      contaDesconsiderados += 1\n",
        "\n",
        "  print(\"Quantidade de resultados OK: {}\\nQuantidade de resultados Não: {}\".format(contaOk, contaNao))\n",
        "  print(\"Percentual de acertos: {:.1f}%\".format(contaOk/(contaOk+contaNao)*100))\n",
        "  print(\"Quantidade de resultados desconsiderados: {}\".format(contaDesconsiderados))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7mrS5_SFP4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#faz a função para gerar modelo 1\n",
        "def rfc_test(X_train, y_train, n_estimators, cv):\n",
        "  np.random.seed(1)\n",
        "  rfc = RandomForestClassifier(n_estimators=n_estimators, random_state=0, n_jobs=-1, criterion='entropy', verbose=0)\n",
        "  cv_scores = cross_val_score(rfc, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "  print('Média dos {} testes: '.format(cv), cv_scores.mean())\n",
        "  return rfc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nQtPnTAFYPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85a5d0ed-eae6-4ee0-db58-d7966dfda47a"
      },
      "source": [
        "#gera o modelo\n",
        "model = rfc_test(X_train, y_train, cv=quantidadeValidacaoCruzada, n_estimators=estimadores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média dos 30 testes:  0.37786731240156696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQS0wMb6IJ8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b609ec64-d968-4648-a416-f17780968456"
      },
      "source": [
        "#fit modelo\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fMmigf-IoCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0bc71eeb-2f44-47a5-eb68-6ffdf2302dd2"
      },
      "source": [
        "#faz predição com dados de validacao\n",
        "valoresPrevistos = model.predict(X_test)\n",
        "#resultado = 1 ou 2\n",
        "mostraResultado(y_test, valoresPrevistos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de resultados OK: 526\n",
            "Quantidade de resultados Não: 1129\n",
            "Percentual de acertos: 31.8%\n",
            "Quantidade de resultados desconsiderados: 1311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4WJodpdTnQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "9b1ed7da-cd09-41ce-c7dd-cf9b24309e43"
      },
      "source": [
        "#gera uma matriz de confusão\n",
        "cm = confusion_matrix(y_test, valoresPrevistos)\n",
        "x_axis_labels = [1, 2]\n",
        "y_axis_labels = [1, 2]\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.ylabel('Real')\n",
        "plt.xlabel('Previsão')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 15.0, 'Previsão')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbqqko1YdZoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#faz a função para gerar modelo 2\n",
        "def abc_test(X_train, y_train, n_estimators, cv):\n",
        "  np.random.seed(1)\n",
        "  abc = AdaBoostClassifier(random_state=2, n_estimators=n_estimators, algorithm='SAMME') \n",
        "  cv_scores = cross_val_score(abc, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "  print('Média dos {} testes: '.format(cv), cv_scores.mean())\n",
        "  return abc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHVF2FDWdnmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4696f7b-d712-4487-b31e-117511af83e0"
      },
      "source": [
        "#gera o modelo\n",
        "model = abc_test(X_train, y_train, cv=quantidadeValidacaoCruzada, n_estimators=estimadores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média dos 30 testes:  0.48062462173343395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOUzr8ZYd5XU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4cbaca2b-087a-403f-91e4-a26426767d12"
      },
      "source": [
        "#fit modelo\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=200, random_state=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7-mwpJ6d9jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "776c3a38-6c23-4f9c-f7e8-2a0f0165be71"
      },
      "source": [
        "#faz predição com dados de validacao\n",
        "valoresPrevistos = model.predict(X_test)\n",
        "#resultado = 1 ou 2\n",
        "mostraResultado(y_test, valoresPrevistos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de resultados OK: 395\n",
            "Quantidade de resultados Não: 901\n",
            "Percentual de acertos: 30.5%\n",
            "Quantidade de resultados desconsiderados: 1670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nalXWmkAeDqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#faz a função para gerar modelo 3\n",
        "def gbc_test(X_train, y_train, n_estimators, cv):\n",
        "  np.random.seed(1)\n",
        "  gbc = GradientBoostingClassifier(random_state=2, n_estimators=n_estimators) \n",
        "  cv_scores = cross_val_score(gbc, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "  print('Média dos {} testes: '.format(cv), cv_scores.mean())\n",
        "  return gbc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDktlVtOeQWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94103352-24be-4aec-f06c-f3d7eda54b04"
      },
      "source": [
        "#gera o modelo\n",
        "model = gbc_test(X_train, y_train, cv=quantidadeValidacaoCruzada, n_estimators=estimadores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média dos 30 testes:  0.42336680575660546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWR8AvJYeTCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "daccebe7-9107-4297-b6bb-0a22042d2912"
      },
      "source": [
        "#fit modelo\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=2, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GJItMpgeVbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8dbdc4b3-15df-4e27-df50-aedd9877eab6"
      },
      "source": [
        "#faz predição com dados de validacao\n",
        "valoresPrevistos = model.predict(X_test)\n",
        "#resultado = 1 ou 2\n",
        "mostraResultado(y_test, valoresPrevistos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de resultados OK: 534\n",
            "Quantidade de resultados Não: 1162\n",
            "Percentual de acertos: 31.5%\n",
            "Quantidade de resultados desconsiderados: 1270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_Ju-Ov5IFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "33ee42d5-316d-4e68-95be-5e56876a45c8"
      },
      "source": [
        "#faz a função para gerar modelo 4 com rede neural Keras\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "1129/1129 [==============================] - 2s 2ms/step - loss: 609.6044 - accuracy: 0.5038\n",
            "Epoch 2/10\n",
            "1129/1129 [==============================] - 2s 1ms/step - loss: 174.3777 - accuracy: 0.5106\n",
            "Epoch 3/10\n",
            "1129/1129 [==============================] - 2s 1ms/step - loss: 190.1673 - accuracy: 0.5088\n",
            "Epoch 4/10\n",
            "1129/1129 [==============================] - 2s 1ms/step - loss: 159.0345 - accuracy: 0.5119\n",
            "Epoch 5/10\n",
            "1129/1129 [==============================] - 2s 1ms/step - loss: 140.6114 - accuracy: 0.5100\n",
            "Epoch 6/10\n",
            "1129/1129 [==============================] - 2s 1ms/step - loss: 128.3135 - accuracy: 0.5072\n",
            "Epoch 7/10\n",
            "1129/1129 [==============================] - 2s 1ms/step - loss: 128.1409 - accuracy: 0.5112\n",
            "Epoch 8/10\n",
            "1129/1129 [==============================] - 2s 1ms/step - loss: 135.7065 - accuracy: 0.5101\n",
            "Epoch 9/10\n",
            "1129/1129 [==============================] - 2s 2ms/step - loss: 106.2263 - accuracy: 0.5148\n",
            "Epoch 10/10\n",
            "1129/1129 [==============================] - 2s 2ms/step - loss: 95.4358 - accuracy: 0.5146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7febb44dbd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzmJ8zuO5rJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bd219699-ed38-4fd3-f58a-29ab5efcf8c0"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93/93 - 0s - loss: 161.7108 - accuracy: 0.3655\n",
            "\n",
            "Test accuracy: 0.3654753863811493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1XpUnap6gKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52f4055e-1688-43b2-b310-a4d0786e1fd8"
      },
      "source": [
        "#faz a função para gerar modelo 5 com rede neural keras\n",
        "model = Sequential()\n",
        "model.add(Dense(288, activation='relu', input_dim=77))\n",
        "model.add(Dense(288, activation='relu'))\n",
        "model.add(Dense(144, activation='relu'))\n",
        "model.add(Dense(144, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=500, validation_data=(X_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 288)               22464     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 288)               83232     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 144)               41616     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 144)               20880     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 145       \n",
            "=================================================================\n",
            "Total params: 168,337\n",
            "Trainable params: 168,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 36102 samples, validate on 2966 samples\n",
            "Epoch 1/200\n",
            "36102/36102 [==============================] - 1s 37us/step - loss: -230177930.1225 - accuracy: 0.4803 - val_loss: -1174394405.8908 - val_accuracy: 0.3618\n",
            "Epoch 2/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -6117018434.2585 - accuracy: 0.4872 - val_loss: -16546400425.8611 - val_accuracy: 0.3618\n",
            "Epoch 3/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -41669571593.3601 - accuracy: 0.4872 - val_loss: -85824629941.5995 - val_accuracy: 0.3618\n",
            "Epoch 4/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -161101894018.8860 - accuracy: 0.4872 - val_loss: -285313288718.1551 - val_accuracy: 0.3618\n",
            "Epoch 5/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -458779760346.7154 - accuracy: 0.4872 - val_loss: -738681348598.6783 - val_accuracy: 0.3618\n",
            "Epoch 6/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -1077510550068.3317 - accuracy: 0.4872 - val_loss: -1626298585808.8740 - val_accuracy: 0.3618\n",
            "Epoch 7/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -2229684508712.7310 - accuracy: 0.4872 - val_loss: -3203295985166.8457 - val_accuracy: 0.3618\n",
            "Epoch 8/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -4182374427729.6318 - accuracy: 0.4872 - val_loss: -5801281585682.2979 - val_accuracy: 0.3618\n",
            "Epoch 9/200\n",
            "36102/36102 [==============================] - 2s 48us/step - loss: -7297965177029.3008 - accuracy: 0.4872 - val_loss: -9816975360055.2402 - val_accuracy: 0.3618\n",
            "Epoch 10/200\n",
            "36102/36102 [==============================] - 2s 42us/step - loss: -12024342624026.7051 - accuracy: 0.4872 - val_loss: -15809981222815.3301 - val_accuracy: 0.3618\n",
            "Epoch 11/200\n",
            "36102/36102 [==============================] - 1s 39us/step - loss: -18884282848678.1133 - accuracy: 0.4872 - val_loss: -24326074914008.1289 - val_accuracy: 0.3618\n",
            "Epoch 12/200\n",
            "36102/36102 [==============================] - 2s 42us/step - loss: -28500732956697.6406 - accuracy: 0.4872 - val_loss: -36169716813627.8984 - val_accuracy: 0.3618\n",
            "Epoch 13/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -41676851268677.3828 - accuracy: 0.4872 - val_loss: -52237315111833.1172 - val_accuracy: 0.3618\n",
            "Epoch 14/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -59321425537483.3828 - accuracy: 0.4872 - val_loss: -73320366299189.8594 - val_accuracy: 0.3618\n",
            "Epoch 15/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -82460210562254.7656 - accuracy: 0.4872 - val_loss: -100827975128070.2188 - val_accuracy: 0.3618\n",
            "Epoch 16/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -112265876662748.6250 - accuracy: 0.4872 - val_loss: -136065517257609.9219 - val_accuracy: 0.3618\n",
            "Epoch 17/200\n",
            "36102/36102 [==============================] - 1s 38us/step - loss: -149987814671040.3438 - accuracy: 0.4872 - val_loss: -180398537331950.2500 - val_accuracy: 0.3618\n",
            "Epoch 18/200\n",
            "36102/36102 [==============================] - 1s 38us/step - loss: -197188421215984.7188 - accuracy: 0.4872 - val_loss: -235303745132697.2812 - val_accuracy: 0.3618\n",
            "Epoch 19/200\n",
            "36102/36102 [==============================] - 1s 40us/step - loss: -255521470083570.0938 - accuracy: 0.4872 - val_loss: -302829590692690.6875 - val_accuracy: 0.3618\n",
            "Epoch 20/200\n",
            "36102/36102 [==============================] - 1s 40us/step - loss: -326692741801409.5625 - accuracy: 0.4872 - val_loss: -385039490356583.7500 - val_accuracy: 0.3618\n",
            "Epoch 21/200\n",
            "36102/36102 [==============================] - 1s 38us/step - loss: -413163541190605.0625 - accuracy: 0.4872 - val_loss: -484171038120321.3125 - val_accuracy: 0.3618\n",
            "Epoch 22/200\n",
            "36102/36102 [==============================] - 1s 39us/step - loss: -516333105304701.3750 - accuracy: 0.4872 - val_loss: -602688417823619.0000 - val_accuracy: 0.3618\n",
            "Epoch 23/200\n",
            "36102/36102 [==============================] - 1s 39us/step - loss: -640346347094220.2500 - accuracy: 0.4872 - val_loss: -743387011003624.7500 - val_accuracy: 0.3618\n",
            "Epoch 24/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -785884184517474.7500 - accuracy: 0.4872 - val_loss: -909034499979931.0000 - val_accuracy: 0.3618\n",
            "Epoch 25/200\n",
            "36102/36102 [==============================] - 1s 37us/step - loss: -956904126436580.7500 - accuracy: 0.4872 - val_loss: -1102427135039497.6250 - val_accuracy: 0.3618\n",
            "Epoch 26/200\n",
            "36102/36102 [==============================] - 1s 37us/step - loss: -1156512208678007.0000 - accuracy: 0.4872 - val_loss: -1327214866156841.5000 - val_accuracy: 0.3618\n",
            "Epoch 27/200\n",
            "36102/36102 [==============================] - 1s 37us/step - loss: -1388052065512331.0000 - accuracy: 0.4872 - val_loss: -1588345617882876.2500 - val_accuracy: 0.3618\n",
            "Epoch 28/200\n",
            "36102/36102 [==============================] - 1s 37us/step - loss: -1654440085770821.0000 - accuracy: 0.4872 - val_loss: -1886673688590439.5000 - val_accuracy: 0.3618\n",
            "Epoch 29/200\n",
            "36102/36102 [==============================] - 1s 37us/step - loss: -1959588247693200.5000 - accuracy: 0.4872 - val_loss: -2229910483628327.5000 - val_accuracy: 0.3618\n",
            "Epoch 30/200\n",
            "36102/36102 [==============================] - 1s 41us/step - loss: -2310434473766121.5000 - accuracy: 0.4872 - val_loss: -2621726714770200.5000 - val_accuracy: 0.3618\n",
            "Epoch 31/200\n",
            "36102/36102 [==============================] - 1s 40us/step - loss: -2707486200814789.5000 - accuracy: 0.4872 - val_loss: -3063464089941280.0000 - val_accuracy: 0.3618\n",
            "Epoch 32/200\n",
            "36102/36102 [==============================] - 1s 40us/step - loss: -3157303495593923.5000 - accuracy: 0.4872 - val_loss: -3564001895524629.5000 - val_accuracy: 0.3618\n",
            "Epoch 33/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -3664457708662643.5000 - accuracy: 0.4872 - val_loss: -4129350450795382.5000 - val_accuracy: 0.3618\n",
            "Epoch 34/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -4235273731998423.5000 - accuracy: 0.4872 - val_loss: -4762740408867002.0000 - val_accuracy: 0.3618\n",
            "Epoch 35/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -4877258529965455.0000 - accuracy: 0.4872 - val_loss: -5471443632483035.0000 - val_accuracy: 0.3618\n",
            "Epoch 36/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -5592103485953614.0000 - accuracy: 0.4872 - val_loss: -6263981340016893.0000 - val_accuracy: 0.3618\n",
            "Epoch 37/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -6390015308889148.0000 - accuracy: 0.4872 - val_loss: -7141501078743319.0000 - val_accuracy: 0.3618\n",
            "Epoch 38/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -7274277484882066.0000 - accuracy: 0.4872 - val_loss: -8121050405774733.0000 - val_accuracy: 0.3618\n",
            "Epoch 39/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -8253636716228542.0000 - accuracy: 0.4872 - val_loss: -9194094003993508.0000 - val_accuracy: 0.3618\n",
            "Epoch 40/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -9333116862917840.0000 - accuracy: 0.4872 - val_loss: -10384097534016298.0000 - val_accuracy: 0.3618\n",
            "Epoch 41/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -10518992124339258.0000 - accuracy: 0.4872 - val_loss: -11688625395695860.0000 - val_accuracy: 0.3618\n",
            "Epoch 42/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -11830911280506534.0000 - accuracy: 0.4872 - val_loss: -13126398485169254.0000 - val_accuracy: 0.3618\n",
            "Epoch 43/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -13272721336077430.0000 - accuracy: 0.4872 - val_loss: -14705805145078172.0000 - val_accuracy: 0.3618\n",
            "Epoch 44/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -14847714357251976.0000 - accuracy: 0.4872 - val_loss: -16422752303447004.0000 - val_accuracy: 0.3618\n",
            "Epoch 45/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -16564171139125112.0000 - accuracy: 0.4872 - val_loss: -18311585202767104.0000 - val_accuracy: 0.3618\n",
            "Epoch 46/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -18434943111463524.0000 - accuracy: 0.4872 - val_loss: -20349625844453092.0000 - val_accuracy: 0.3618\n",
            "Epoch 47/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -20467580273157984.0000 - accuracy: 0.4872 - val_loss: -22572165307217216.0000 - val_accuracy: 0.3618\n",
            "Epoch 48/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -22697578411108696.0000 - accuracy: 0.4872 - val_loss: -24995213493630440.0000 - val_accuracy: 0.3618\n",
            "Epoch 49/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -25089260247316524.0000 - accuracy: 0.4872 - val_loss: -27607655633622796.0000 - val_accuracy: 0.3618\n",
            "Epoch 50/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -27697470389866424.0000 - accuracy: 0.4872 - val_loss: -30450593688136356.0000 - val_accuracy: 0.3618\n",
            "Epoch 51/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -30505467484283916.0000 - accuracy: 0.4872 - val_loss: -33499622081842340.0000 - val_accuracy: 0.3618\n",
            "Epoch 52/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -33547765777476708.0000 - accuracy: 0.4872 - val_loss: -36819714241563736.0000 - val_accuracy: 0.3618\n",
            "Epoch 53/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -36820810042275576.0000 - accuracy: 0.4872 - val_loss: -40377568233329008.0000 - val_accuracy: 0.3618\n",
            "Epoch 54/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -40359844811956872.0000 - accuracy: 0.4872 - val_loss: -44202025919536480.0000 - val_accuracy: 0.3618\n",
            "Epoch 55/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -44133422869429864.0000 - accuracy: 0.4872 - val_loss: -48309658642301160.0000 - val_accuracy: 0.3618\n",
            "Epoch 56/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -48217553760630368.0000 - accuracy: 0.4872 - val_loss: -52727824465769840.0000 - val_accuracy: 0.3618\n",
            "Epoch 57/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -52573081224506232.0000 - accuracy: 0.4872 - val_loss: -57462350253041872.0000 - val_accuracy: 0.3618\n",
            "Epoch 58/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -57255824817439120.0000 - accuracy: 0.4872 - val_loss: -62531648120560280.0000 - val_accuracy: 0.3618\n",
            "Epoch 59/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -62246298430796016.0000 - accuracy: 0.4872 - val_loss: -67934502355097256.0000 - val_accuracy: 0.3618\n",
            "Epoch 60/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -67600435037028104.0000 - accuracy: 0.4872 - val_loss: -73716550149647696.0000 - val_accuracy: 0.3618\n",
            "Epoch 61/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -73312703384952448.0000 - accuracy: 0.4872 - val_loss: -79896268641767728.0000 - val_accuracy: 0.3618\n",
            "Epoch 62/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -79365572961552032.0000 - accuracy: 0.4872 - val_loss: -86442549751141488.0000 - val_accuracy: 0.3618\n",
            "Epoch 63/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -85834080816149664.0000 - accuracy: 0.4872 - val_loss: -93457285677440816.0000 - val_accuracy: 0.3618\n",
            "Epoch 64/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -92743254389635504.0000 - accuracy: 0.4872 - val_loss: -100900193114375040.0000 - val_accuracy: 0.3618\n",
            "Epoch 65/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -100060976334384144.0000 - accuracy: 0.4872 - val_loss: -108787996363396832.0000 - val_accuracy: 0.3618\n",
            "Epoch 66/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -107827162568887552.0000 - accuracy: 0.4872 - val_loss: -117175240431803408.0000 - val_accuracy: 0.3618\n",
            "Epoch 67/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -116079392430936944.0000 - accuracy: 0.4872 - val_loss: -126082033771455440.0000 - val_accuracy: 0.3618\n",
            "Epoch 68/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -124850461852528048.0000 - accuracy: 0.4872 - val_loss: -135505677857007408.0000 - val_accuracy: 0.3618\n",
            "Epoch 69/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -134134839032371840.0000 - accuracy: 0.4872 - val_loss: -145510950254057888.0000 - val_accuracy: 0.3618\n",
            "Epoch 70/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -143933975123115232.0000 - accuracy: 0.4872 - val_loss: -156112078859932864.0000 - val_accuracy: 0.3618\n",
            "Epoch 71/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -154308229886286080.0000 - accuracy: 0.4872 - val_loss: -167272722771821888.0000 - val_accuracy: 0.3618\n",
            "Epoch 72/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -165301358931145600.0000 - accuracy: 0.4872 - val_loss: -179038879780412384.0000 - val_accuracy: 0.3618\n",
            "Epoch 73/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -176865937523850976.0000 - accuracy: 0.4872 - val_loss: -191517500954454944.0000 - val_accuracy: 0.3618\n",
            "Epoch 74/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -189138861868298592.0000 - accuracy: 0.4872 - val_loss: -204717563198433856.0000 - val_accuracy: 0.3618\n",
            "Epoch 75/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -202008614004969664.0000 - accuracy: 0.4872 - val_loss: -218538429978078880.0000 - val_accuracy: 0.3618\n",
            "Epoch 76/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -215573759065293984.0000 - accuracy: 0.4872 - val_loss: -233140784644621600.0000 - val_accuracy: 0.3618\n",
            "Epoch 77/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -229896190802470464.0000 - accuracy: 0.4872 - val_loss: -248501454960386848.0000 - val_accuracy: 0.3618\n",
            "Epoch 78/200\n",
            "36102/36102 [==============================] - 1s 38us/step - loss: -244992202501264384.0000 - accuracy: 0.4872 - val_loss: -264686699336615744.0000 - val_accuracy: 0.3618\n",
            "Epoch 79/200\n",
            "36102/36102 [==============================] - 1s 37us/step - loss: -260725432520482624.0000 - accuracy: 0.4872 - val_loss: -281610111372179744.0000 - val_accuracy: 0.3618\n",
            "Epoch 80/200\n",
            "36102/36102 [==============================] - 1s 37us/step - loss: -277380116489820736.0000 - accuracy: 0.4872 - val_loss: -299555476985262336.0000 - val_accuracy: 0.3618\n",
            "Epoch 81/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -294877185694070272.0000 - accuracy: 0.4872 - val_loss: -318246822255822144.0000 - val_accuracy: 0.3618\n",
            "Epoch 82/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -313236285955592256.0000 - accuracy: 0.4872 - val_loss: -337935735362748096.0000 - val_accuracy: 0.3618\n",
            "Epoch 83/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -332413344748361088.0000 - accuracy: 0.4872 - val_loss: -358522329650470080.0000 - val_accuracy: 0.3618\n",
            "Epoch 84/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -352592464490479232.0000 - accuracy: 0.4872 - val_loss: -380112244447382976.0000 - val_accuracy: 0.3618\n",
            "Epoch 85/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -373731095637857280.0000 - accuracy: 0.4872 - val_loss: -402768912024116736.0000 - val_accuracy: 0.3618\n",
            "Epoch 86/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -395867558966556224.0000 - accuracy: 0.4872 - val_loss: -426452577537814592.0000 - val_accuracy: 0.3618\n",
            "Epoch 87/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -419121458887072448.0000 - accuracy: 0.4872 - val_loss: -451453599382453376.0000 - val_accuracy: 0.3618\n",
            "Epoch 88/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -443319779083028800.0000 - accuracy: 0.4872 - val_loss: -477307243515007808.0000 - val_accuracy: 0.3618\n",
            "Epoch 89/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -468682412640482944.0000 - accuracy: 0.4872 - val_loss: -504398943833904576.0000 - val_accuracy: 0.3618\n",
            "Epoch 90/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -495140058350305024.0000 - accuracy: 0.4872 - val_loss: -532857782948639104.0000 - val_accuracy: 0.3618\n",
            "Epoch 91/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -522892195102711872.0000 - accuracy: 0.4872 - val_loss: -562493256938959168.0000 - val_accuracy: 0.3618\n",
            "Epoch 92/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -551750413862048512.0000 - accuracy: 0.4872 - val_loss: -593426453878659840.0000 - val_accuracy: 0.3618\n",
            "Epoch 93/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -581904356862789760.0000 - accuracy: 0.4872 - val_loss: -625696117535329792.0000 - val_accuracy: 0.3618\n",
            "Epoch 94/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -613358327478004224.0000 - accuracy: 0.4872 - val_loss: -659297453810288000.0000 - val_accuracy: 0.3618\n",
            "Epoch 95/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -646218123691581824.0000 - accuracy: 0.4872 - val_loss: -694357930428495616.0000 - val_accuracy: 0.3618\n",
            "Epoch 96/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -680487525935116032.0000 - accuracy: 0.4872 - val_loss: -731036189059117568.0000 - val_accuracy: 0.3618\n",
            "Epoch 97/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -716129774858139392.0000 - accuracy: 0.4872 - val_loss: -769068112394109440.0000 - val_accuracy: 0.3618\n",
            "Epoch 98/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -753206549105251840.0000 - accuracy: 0.4872 - val_loss: -808736530523046272.0000 - val_accuracy: 0.3618\n",
            "Epoch 99/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -791851181927664256.0000 - accuracy: 0.4872 - val_loss: -849997358256597248.0000 - val_accuracy: 0.3618\n",
            "Epoch 100/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -832075853937333248.0000 - accuracy: 0.4872 - val_loss: -892867703454461440.0000 - val_accuracy: 0.3618\n",
            "Epoch 101/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -873900223453925120.0000 - accuracy: 0.4872 - val_loss: -937545154769349632.0000 - val_accuracy: 0.3618\n",
            "Epoch 102/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -917402505317650048.0000 - accuracy: 0.4872 - val_loss: -983884222967295488.0000 - val_accuracy: 0.3618\n",
            "Epoch 103/200\n",
            "36102/36102 [==============================] - 1s 36us/step - loss: -962414526785538048.0000 - accuracy: 0.4872 - val_loss: -1032174538446767104.0000 - val_accuracy: 0.3618\n",
            "Epoch 104/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1009548017268096640.0000 - accuracy: 0.4872 - val_loss: -1082280858265568000.0000 - val_accuracy: 0.3618\n",
            "Epoch 105/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1058233355997470976.0000 - accuracy: 0.4872 - val_loss: -1134277874470951168.0000 - val_accuracy: 0.3618\n",
            "Epoch 106/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -1108964911197663488.0000 - accuracy: 0.4872 - val_loss: -1188434755507360512.0000 - val_accuracy: 0.3618\n",
            "Epoch 107/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -1161514291770936832.0000 - accuracy: 0.4872 - val_loss: -1244541055229212928.0000 - val_accuracy: 0.3618\n",
            "Epoch 108/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1216017741341700864.0000 - accuracy: 0.4872 - val_loss: -1302502530318897152.0000 - val_accuracy: 0.3618\n",
            "Epoch 109/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1272357637318383104.0000 - accuracy: 0.4872 - val_loss: -1362699415418543616.0000 - val_accuracy: 0.3618\n",
            "Epoch 110/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -1331034770437917440.0000 - accuracy: 0.4872 - val_loss: -1425317116881177600.0000 - val_accuracy: 0.3618\n",
            "Epoch 111/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1391940541287055616.0000 - accuracy: 0.4872 - val_loss: -1489993564712221184.0000 - val_accuracy: 0.3618\n",
            "Epoch 112/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1455080631109868288.0000 - accuracy: 0.4872 - val_loss: -1557466496182270720.0000 - val_accuracy: 0.3618\n",
            "Epoch 113/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -1520133124132410368.0000 - accuracy: 0.4872 - val_loss: -1626532297487442176.0000 - val_accuracy: 0.3618\n",
            "Epoch 114/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1587510973815335936.0000 - accuracy: 0.4872 - val_loss: -1698485551541875456.0000 - val_accuracy: 0.3618\n",
            "Epoch 115/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1657544685832919552.0000 - accuracy: 0.4872 - val_loss: -1773092205368386304.0000 - val_accuracy: 0.3618\n",
            "Epoch 116/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -1730163858168133120.0000 - accuracy: 0.4872 - val_loss: -1850309037891468544.0000 - val_accuracy: 0.3618\n",
            "Epoch 117/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -1804752234075710720.0000 - accuracy: 0.4872 - val_loss: -1929724007499318528.0000 - val_accuracy: 0.3618\n",
            "Epoch 118/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -1882118072130608384.0000 - accuracy: 0.4872 - val_loss: -2012471253485265152.0000 - val_accuracy: 0.3618\n",
            "Epoch 119/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -1962340488349541376.0000 - accuracy: 0.4872 - val_loss: -2097782180336324096.0000 - val_accuracy: 0.3618\n",
            "Epoch 120/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -2045206763193100800.0000 - accuracy: 0.4872 - val_loss: -2185796941680159488.0000 - val_accuracy: 0.3618\n",
            "Epoch 121/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -2130749108442991872.0000 - accuracy: 0.4872 - val_loss: -2276865837157818624.0000 - val_accuracy: 0.3618\n",
            "Epoch 122/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -2219052423904336896.0000 - accuracy: 0.4872 - val_loss: -2370901715644591616.0000 - val_accuracy: 0.3618\n",
            "Epoch 123/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -2310412801279057920.0000 - accuracy: 0.4872 - val_loss: -2467858993746076672.0000 - val_accuracy: 0.3618\n",
            "Epoch 124/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -2404512606788281344.0000 - accuracy: 0.4872 - val_loss: -2568389456746811392.0000 - val_accuracy: 0.3618\n",
            "Epoch 125/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -2501698536066282496.0000 - accuracy: 0.4872 - val_loss: -2671775283235123200.0000 - val_accuracy: 0.3618\n",
            "Epoch 126/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -2602169620049444352.0000 - accuracy: 0.4872 - val_loss: -2778407875254662144.0000 - val_accuracy: 0.3618\n",
            "Epoch 127/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -2705772175034491392.0000 - accuracy: 0.4872 - val_loss: -2888537904960179712.0000 - val_accuracy: 0.3618\n",
            "Epoch 128/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -2812235827999581184.0000 - accuracy: 0.4872 - val_loss: -3002163093441449984.0000 - val_accuracy: 0.3618\n",
            "Epoch 129/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -2922910935293850112.0000 - accuracy: 0.4872 - val_loss: -3119657336559685120.0000 - val_accuracy: 0.3618\n",
            "Epoch 130/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -3036664079752214016.0000 - accuracy: 0.4872 - val_loss: -3240305668538056192.0000 - val_accuracy: 0.3618\n",
            "Epoch 131/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -3153301561000220160.0000 - accuracy: 0.4872 - val_loss: -3364457233436821504.0000 - val_accuracy: 0.3618\n",
            "Epoch 132/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -3274172924839044608.0000 - accuracy: 0.4872 - val_loss: -3492530144462929920.0000 - val_accuracy: 0.3618\n",
            "Epoch 133/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -3399284022097701376.0000 - accuracy: 0.4872 - val_loss: -3625751395797324288.0000 - val_accuracy: 0.3618\n",
            "Epoch 134/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -3526871405032541696.0000 - accuracy: 0.4872 - val_loss: -3761398637797910016.0000 - val_accuracy: 0.3618\n",
            "Epoch 135/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -3659057032423936512.0000 - accuracy: 0.4872 - val_loss: -3901858121162566144.0000 - val_accuracy: 0.3618\n",
            "Epoch 136/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -3795009350970670080.0000 - accuracy: 0.4872 - val_loss: -4046245778673671680.0000 - val_accuracy: 0.3618\n",
            "Epoch 137/200\n",
            "36102/36102 [==============================] - 1s 31us/step - loss: -3934675849398969856.0000 - accuracy: 0.4872 - val_loss: -4194645826768207360.0000 - val_accuracy: 0.3618\n",
            "Epoch 138/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -4079111762430959104.0000 - accuracy: 0.4872 - val_loss: -4347815123135007744.0000 - val_accuracy: 0.3618\n",
            "Epoch 139/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -4227238740885532160.0000 - accuracy: 0.4872 - val_loss: -4505238123601823744.0000 - val_accuracy: 0.3618\n",
            "Epoch 140/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -4380260810952184320.0000 - accuracy: 0.4872 - val_loss: -4667568043170480128.0000 - val_accuracy: 0.3618\n",
            "Epoch 141/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -4536607341498258432.0000 - accuracy: 0.4872 - val_loss: -4833364049330162688.0000 - val_accuracy: 0.3618\n",
            "Epoch 142/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -4698243328496705536.0000 - accuracy: 0.4872 - val_loss: -5005245908140719104.0000 - val_accuracy: 0.3618\n",
            "Epoch 143/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -4863792599505758208.0000 - accuracy: 0.4872 - val_loss: -5181005840475087872.0000 - val_accuracy: 0.3618\n",
            "Epoch 144/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -5034398374694600704.0000 - accuracy: 0.4872 - val_loss: -5361843777922385920.0000 - val_accuracy: 0.3618\n",
            "Epoch 145/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -5209573686433110016.0000 - accuracy: 0.4872 - val_loss: -5548179388797882368.0000 - val_accuracy: 0.3618\n",
            "Epoch 146/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -5389791525713612800.0000 - accuracy: 0.4872 - val_loss: -5739656681560188928.0000 - val_accuracy: 0.3618\n",
            "Epoch 147/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -5574608979347990528.0000 - accuracy: 0.4872 - val_loss: -5935297593166131200.0000 - val_accuracy: 0.3618\n",
            "Epoch 148/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -5764811790835591168.0000 - accuracy: 0.4872 - val_loss: -6137061580117586944.0000 - val_accuracy: 0.3618\n",
            "Epoch 149/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -5959757068064999424.0000 - accuracy: 0.4872 - val_loss: -6344003480199427072.0000 - val_accuracy: 0.3618\n",
            "Epoch 150/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -6160156921427796992.0000 - accuracy: 0.4872 - val_loss: -6557412395912774656.0000 - val_accuracy: 0.3618\n",
            "Epoch 151/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -6366662184023773184.0000 - accuracy: 0.4872 - val_loss: -6776317035515663360.0000 - val_accuracy: 0.3618\n",
            "Epoch 152/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -6578142508835443712.0000 - accuracy: 0.4872 - val_loss: -6999565261328497664.0000 - val_accuracy: 0.3618\n",
            "Epoch 153/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -6794607132040675328.0000 - accuracy: 0.4872 - val_loss: -7229840937120759808.0000 - val_accuracy: 0.3618\n",
            "Epoch 154/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -7017110560759724032.0000 - accuracy: 0.4872 - val_loss: -7465057424479323136.0000 - val_accuracy: 0.3618\n",
            "Epoch 155/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -7245216100964704256.0000 - accuracy: 0.4872 - val_loss: -7706936695403503616.0000 - val_accuracy: 0.3618\n",
            "Epoch 156/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -7479225348433196032.0000 - accuracy: 0.4872 - val_loss: -7956239051433459712.0000 - val_accuracy: 0.3618\n",
            "Epoch 157/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -7720198045620031488.0000 - accuracy: 0.4872 - val_loss: -8211392742550808576.0000 - val_accuracy: 0.3618\n",
            "Epoch 158/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -7965450138850380800.0000 - accuracy: 0.4872 - val_loss: -8471622846602247168.0000 - val_accuracy: 0.3618\n",
            "Epoch 159/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -8218494655548313600.0000 - accuracy: 0.4872 - val_loss: -8738991338983843840.0000 - val_accuracy: 0.3618\n",
            "Epoch 160/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -8477046114090394624.0000 - accuracy: 0.4872 - val_loss: -9013643313711479808.0000 - val_accuracy: 0.3618\n",
            "Epoch 161/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -8742162284285408256.0000 - accuracy: 0.4872 - val_loss: -9295597780547893248.0000 - val_accuracy: 0.3618\n",
            "Epoch 162/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -9014158857082309632.0000 - accuracy: 0.4872 - val_loss: -9583073472826071040.0000 - val_accuracy: 0.3618\n",
            "Epoch 163/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -9293256248837933056.0000 - accuracy: 0.4872 - val_loss: -9877875827933579264.0000 - val_accuracy: 0.3618\n",
            "Epoch 164/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -9578420109932007424.0000 - accuracy: 0.4872 - val_loss: -10180269316599527424.0000 - val_accuracy: 0.3618\n",
            "Epoch 165/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -9872006885379655680.0000 - accuracy: 0.4872 - val_loss: -10491439834401990656.0000 - val_accuracy: 0.3618\n",
            "Epoch 166/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -10170253341858953216.0000 - accuracy: 0.4872 - val_loss: -10808528191434299392.0000 - val_accuracy: 0.3618\n",
            "Epoch 167/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -10478186685030668288.0000 - accuracy: 0.4872 - val_loss: -11134160030360508416.0000 - val_accuracy: 0.3618\n",
            "Epoch 168/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -10791918942249760768.0000 - accuracy: 0.4872 - val_loss: -11466029332765562880.0000 - val_accuracy: 0.3618\n",
            "Epoch 169/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -11115216820401938432.0000 - accuracy: 0.4872 - val_loss: -11808254069225291776.0000 - val_accuracy: 0.3618\n",
            "Epoch 170/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -11444003984986191872.0000 - accuracy: 0.4872 - val_loss: -12156797226731419648.0000 - val_accuracy: 0.3618\n",
            "Epoch 171/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -11781300518089011200.0000 - accuracy: 0.4872 - val_loss: -12514296003570546688.0000 - val_accuracy: 0.3618\n",
            "Epoch 172/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -12125792764198719488.0000 - accuracy: 0.4872 - val_loss: -12878515816219957248.0000 - val_accuracy: 0.3618\n",
            "Epoch 173/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -12478928973949161472.0000 - accuracy: 0.4872 - val_loss: -13252647417025632256.0000 - val_accuracy: 0.3618\n",
            "Epoch 174/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -12839282909963556864.0000 - accuracy: 0.4872 - val_loss: -13635670963356067840.0000 - val_accuracy: 0.3618\n",
            "Epoch 175/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -13208531122690142208.0000 - accuracy: 0.4872 - val_loss: -14027066788797169664.0000 - val_accuracy: 0.3618\n",
            "Epoch 176/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -13587449774265520128.0000 - accuracy: 0.4872 - val_loss: -14428381202610755584.0000 - val_accuracy: 0.3618\n",
            "Epoch 177/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -13973847586135531520.0000 - accuracy: 0.4872 - val_loss: -14836801118013247488.0000 - val_accuracy: 0.3618\n",
            "Epoch 178/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -14369849585172391936.0000 - accuracy: 0.4872 - val_loss: -15255052992431079424.0000 - val_accuracy: 0.3618\n",
            "Epoch 179/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -14774638967449884672.0000 - accuracy: 0.4872 - val_loss: -15683255862270111744.0000 - val_accuracy: 0.3618\n",
            "Epoch 180/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -15187193975043104768.0000 - accuracy: 0.4872 - val_loss: -16119758356707362816.0000 - val_accuracy: 0.3618\n",
            "Epoch 181/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -15609412690105714688.0000 - accuracy: 0.4872 - val_loss: -16567316844630575104.0000 - val_accuracy: 0.3618\n",
            "Epoch 182/200\n",
            "36102/36102 [==============================] - 1s 35us/step - loss: -16042020584066058240.0000 - accuracy: 0.4872 - val_loss: -17025168161914019840.0000 - val_accuracy: 0.3618\n",
            "Epoch 183/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -16482414525228029952.0000 - accuracy: 0.4872 - val_loss: -17491719814617655296.0000 - val_accuracy: 0.3618\n",
            "Epoch 184/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -16934220967843704832.0000 - accuracy: 0.4872 - val_loss: -17969234030492475392.0000 - val_accuracy: 0.3618\n",
            "Epoch 185/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -17394557619995170816.0000 - accuracy: 0.4872 - val_loss: -18455887229838368768.0000 - val_accuracy: 0.3618\n",
            "Epoch 186/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -17866653944807960576.0000 - accuracy: 0.4872 - val_loss: -18955952434388750336.0000 - val_accuracy: 0.3618\n",
            "Epoch 187/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -18347108457148299264.0000 - accuracy: 0.4872 - val_loss: -19464788190372954112.0000 - val_accuracy: 0.3618\n",
            "Epoch 188/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -18838188423269064704.0000 - accuracy: 0.4872 - val_loss: -19983932037650542592.0000 - val_accuracy: 0.3618\n",
            "Epoch 189/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -19339139491638509568.0000 - accuracy: 0.4872 - val_loss: -20513703788047343616.0000 - val_accuracy: 0.3618\n",
            "Epoch 190/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -19851279136791089152.0000 - accuracy: 0.4872 - val_loss: -21055782581912985600.0000 - val_accuracy: 0.3618\n",
            "Epoch 191/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -20374533848172761088.0000 - accuracy: 0.4872 - val_loss: -21608386903466565632.0000 - val_accuracy: 0.3618\n",
            "Epoch 192/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -20908566098677395456.0000 - accuracy: 0.4872 - val_loss: -22175430302348980224.0000 - val_accuracy: 0.3618\n",
            "Epoch 193/200\n",
            "36102/36102 [==============================] - 1s 34us/step - loss: -21454176593531703296.0000 - accuracy: 0.4872 - val_loss: -22750579443302154240.0000 - val_accuracy: 0.3618\n",
            "Epoch 194/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -22011736876907896832.0000 - accuracy: 0.4872 - val_loss: -23340939741169979392.0000 - val_accuracy: 0.3618\n",
            "Epoch 195/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -22576902788536832000.0000 - accuracy: 0.4872 - val_loss: -23939272770599436288.0000 - val_accuracy: 0.3618\n",
            "Epoch 196/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -23160102876484042752.0000 - accuracy: 0.4872 - val_loss: -24556589914412515328.0000 - val_accuracy: 0.3618\n",
            "Epoch 197/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -23749905173292470272.0000 - accuracy: 0.4872 - val_loss: -25180791555011686400.0000 - val_accuracy: 0.3618\n",
            "Epoch 198/200\n",
            "36102/36102 [==============================] - 1s 33us/step - loss: -24353544074299899904.0000 - accuracy: 0.4872 - val_loss: -25818232430690525184.0000 - val_accuracy: 0.3618\n",
            "Epoch 199/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -24970810744172503040.0000 - accuracy: 0.4872 - val_loss: -26469878981772021760.0000 - val_accuracy: 0.3618\n",
            "Epoch 200/200\n",
            "36102/36102 [==============================] - 1s 32us/step - loss: -25599435708801974272.0000 - accuracy: 0.4872 - val_loss: -27134469519034007552.0000 - val_accuracy: 0.3618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MHOuQGE7ltu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5ba44291-8e58-408a-8d2d-436316c3acdd"
      },
      "source": [
        "epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "plt.plot(epochs, history.history['accuracy'], 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, history.history['val_accuracy'], 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7rsJjFB82Xc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "008bea70-fb6e-4023-cb1c-a049f946ba9d"
      },
      "source": [
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "plt.plot(epochs, history.history['loss'], 'bo', label='Training loss')\n",
        "plt.plot(epochs, history.history['val_loss'], 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCZuGk6iDcih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bad0358e-4099-4878-b2f9-b6507f1d8cee"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nmz7LdRDU2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0eaa8ecd-c812-4836-f2af-485921b60144"
      },
      "source": [
        "len(valoresPrevistos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g9C6qZ0FcT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "17a2d75a-c2ff-43c8-f226-b8ffe2985364"
      },
      "source": [
        "valoresPrevistos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH6lV7Hy_MPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "097a109c-4dcb-45d4-d265-e46a2d7f3ce0"
      },
      "source": [
        "#faz predição com dados de validacao\n",
        "valoresPrevistos = model.predict(X_test)\n",
        "#resultado = 1 ou 2\n",
        "mostraResultado(y_test, valoresPrevistos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de resultados OK: 1073\n",
            "Quantidade de resultados Não: 1893\n",
            "Percentual de acertos: 36.2%\n",
            "Quantidade de resultados desconsiderados: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}